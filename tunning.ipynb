{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"unicamp.png\" width=\"150\" height=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\n",
    "import os\n",
    "\n",
    "# Numerical and IO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NLP\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pyswarm import pso\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'augmented/'\n",
    "files_path = os.listdir(folder)\n",
    "files = {}\n",
    "\n",
    "# Get in order\n",
    "for i in range(1, len(files_path)+1):\n",
    "    \n",
    "    file = [f for f in files_path if f'{i}' == f.split('_')[0]][0]\n",
    "    files[file] = pd.read_csv(folder+file)\n",
    "    files[file].columns = ['question', 'answer']\n",
    "    files[file].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for f in files:\n",
    "    \n",
    "    for indx, row in files[f].iterrows():\n",
    "        \n",
    "        corpus.append(row['question'])\n",
    "        corpus.append(row['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IO objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file: str, data):\n",
    "    \n",
    "    folder = 'pickles/'\n",
    "    with open(f'{folder}{file}.pickle', 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load(file: str):\n",
    "\n",
    "    folder = 'pickles/'\n",
    "    with open(f'{folder}{file}.pickle', 'rb') as handle:\n",
    "        pick = pickle.load(handle)\n",
    "    \n",
    "    return pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Prepare data for hierarquical classifier.\n",
    "- Which subject?\n",
    "- Which question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which subject?\n",
    "class_sub = {}\n",
    "X_sub, y_sub = [], []\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "\n",
    "    class_sub[str(i+1)] = f\n",
    "    X_sub.extend(files[f]['question'].values)\n",
    "    y_sub.extend([str(i+1)]*len(files[f]['question'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which question?\n",
    "class_que = {}\n",
    "X_que, y_que = [], []\n",
    "count = 0\n",
    "last = ''\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    \n",
    "    for j, row in files[f].iterrows():\n",
    "        \n",
    "        que = row['question']\n",
    "        ans = row['answer']\n",
    "        \n",
    "        if last != ans:\n",
    "            last = ans\n",
    "            count += 1\n",
    "        \n",
    "        class_que[str(count)] = ans\n",
    "        X_que.append(que)\n",
    "        y_que.append(str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = [x.replace('\\n', '') for x in X_sub]\n",
    "X_que = [x.replace('\\n', '') for x in X_que]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 800, 800)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_sub), len(y_sub), len(X_que), len(y_que)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X: list, y: list):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str):\n",
    "    \n",
    "    tokenized = word_tokenize(text.lower())\n",
    "    return model.infer_vector(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_it_vector(X: list):\n",
    "    \n",
    "    vectors = []\n",
    "    \n",
    "    for text in X:\n",
    "        vectors.append(get_embedding(text))\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y):\n",
    "    \n",
    "    return cross_val_score(model, X, y, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(classes_len):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(classes_len, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(ys):\n",
    "    \n",
    "    y_ohe = []\n",
    "    ys = list(map(int, ys))\n",
    "    maxi = np.amax(ys)\n",
    "    \n",
    "    for y in ys:\n",
    "        y_ohe.append([1 if i == y else 0 for i in range(maxi)])\n",
    "    \n",
    "    return y_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_pso():\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        super(model_pso, self).__init__()\n",
    "        \n",
    "    def model_set(self, model, dict_params, extra_params = {}):\n",
    "        self.model = model\n",
    "        self.dict_params = dict_params\n",
    "        self.extra_params = extra_params\n",
    "\n",
    "    def model_fit(self, params):\n",
    "        \n",
    "        scores = cross_val_score(self.model(**params), self.X, self.y, cv=5, scoring='f1_macro')\n",
    "        \n",
    "        return scores.mean()\n",
    "\n",
    "    def model_optimize(self, params_value):\n",
    "        '''\n",
    "        Modelo ajeitado para ser aplicado com o PSO.\n",
    "        ''' \n",
    "        params = self.extra_params\n",
    "        for key, value in zip(self.dict_params.keys(), params_value):\n",
    "            params[key] = self.dict_params[key](value)\n",
    "        \n",
    "        score = self.model_fit(params)\n",
    "        \n",
    "        return 1 - score\n",
    "    \n",
    "    def model_predict(self, X_test, y_test, best_params):\n",
    "        params = self.extra_params\n",
    "        for key, value in zip(self.dict_params.keys(), best_params):\n",
    "            params[key] = self.dict_params[key](value)\n",
    "            \n",
    "        clf = self.model(**params)\n",
    "        clf.fit(self.X, self.y)\n",
    "        pred = clf.predict(X_test)\n",
    "        return clf, f1_score(y_test, pred, average='macro')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(X_sub, y_sub)\n",
    "\n",
    "# Make X vector\n",
    "X_train_vec = make_it_vector(X_train)\n",
    "X_test_vec = make_it_vector(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pso = model_pso(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for RandomForestClassifier(random_state=42) using train dataset = 0.7487754934936588\n",
      "f1-Score for RandomForestClassifier(random_state=42) using test dataset = 0.8530094905094905\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(rf_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "pred = rf_model.predict(X_test_vec)\n",
    "\n",
    "print(f\"f1-Score for {rf_model} using train dataset = {evaluate(rf_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {rf_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "New best for swarm at iteration 1: [ 0.         74.69157443] 0.26131525647909926\n",
      "New best for swarm at iteration 1: [  0.         204.45090028] 0.23258916745449254\n",
      "Best after iteration 1: [  0.         204.45090028] 0.23258916745449254\n",
      "New best for swarm at iteration 2: [  0.         179.91192881] 0.23228728892796235\n",
      "Best after iteration 2: [  0.         179.91192881] 0.23228728892796235\n",
      "New best for swarm at iteration 3: [  0.         286.98393573] 0.2230096429842946\n",
      "Best after iteration 3: [  0.         286.98393573] 0.2230096429842946\n",
      "New best for swarm at iteration 4: [  0.         280.47590359] 0.2217753378587357\n",
      "New best for swarm at iteration 4: [  0.         276.61437201] 0.21977159431499682\n",
      "Best after iteration 4: [  0.         276.61437201] 0.21977159431499682\n",
      "New best for swarm at iteration 5: [  0.         277.07917241] 0.21947981093497815\n",
      "Best after iteration 5: [  0.         277.07917241] 0.21947981093497815\n",
      "Best after iteration 6: [  0.         277.07917241] 0.21947981093497815\n",
      "Best after iteration 7: [  0.         277.07917241] 0.21947981093497815\n",
      "Best after iteration 8: [  0.         277.07917241] 0.21947981093497815\n",
      "Best after iteration 9: [  0.         277.07917241] 0.21947981093497815\n",
      "Best after iteration 10: [  0.         277.07917241] 0.21947981093497815\n",
      "Best after iteration 11: [  0.         277.07917241] 0.21947981093497815\n",
      "Stopping search: maximum iterations reached --> 11\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "rf_model = RandomForestClassifier\n",
    "\n",
    "# Set hyperparameters to optimize and variables's type\n",
    "param_to_opt = {'ccp_alpha' : float, 'n_estimators' : int}\n",
    "\n",
    "# Set lower and upper boundarys\n",
    "lb = [0.0, 1]\n",
    "ub = [0.04, 300]\n",
    "\n",
    "# Set model in class\n",
    "m_pso.model_set(rf_model, param_to_opt, extra_params= {'random_state' : 42})\n",
    "\n",
    "# Seek best hyperparameters\n",
    "best_pso = pso(m_pso.model_optimize, lb, ub, swarmsize= 11, maxiter= 11, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for RandomForestClassifier(n_estimators=277, random_state=42) using train dataset = 0.7805201890650219\n",
      "f1-Score for RandomForestClassifier(n_estimators=277, random_state=42) using test dataset = 0.8718649406149406\n"
     ]
    }
   ],
   "source": [
    "model_test, test_score = m_pso.model_predict(X_test_vec, y_test, best_pso[0])\n",
    "print(f\"f1-Score for {model_test} using train dataset = {evaluate(model_test, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {model_test} using test dataset = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for MLPClassifier(max_iter=300, random_state=42) using train dataset = 0.7534351410888883\n",
      "f1-Score for MLPClassifier(max_iter=300, random_state=42) using test dataset = 0.7338108072483072\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "mlp_model = MLPClassifier(max_iter=300, random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(mlp_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "mlp_model.fit(X_train_vec, y_train)\n",
    "pred = mlp_model.predict(X_test_vec)\n",
    "f1_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f\"f1-Score for {mlp_model} using train dataset = {evaluate(mlp_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {mlp_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "New best for swarm at iteration 1: [50.] 0.2818760410621446\n",
      "Best after iteration 1: [50.] 0.2818760410621446\n",
      "Best after iteration 2: [50.] 0.2818760410621446\n",
      "Best after iteration 3: [50.] 0.2818760410621446\n",
      "New best for swarm at iteration 4: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 4: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 5: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 6: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 7: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 8: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 9: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 10: [39.27177584] 0.2732395696212748\n",
      "Best after iteration 11: [39.27177584] 0.2732395696212748\n",
      "Stopping search: maximum iterations reached --> 11\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "mlp_model = MLPClassifier\n",
    "\n",
    "# Set hyperparameters to optimize and variables's type\n",
    "param_to_opt = {'hidden_layer_sizes' : int}\n",
    "\n",
    "# Set lower and upper boundarys\n",
    "lb = [3]\n",
    "ub = [100]\n",
    "\n",
    "# Set model in class\n",
    "m_pso.model_set(mlp_model, param_to_opt, extra_params= {'max_iter': 200, 'random_state':42})\n",
    "\n",
    "# Seek best hyperparameters\n",
    "best_pso = pso(m_pso.model_optimize, lb, ub, swarmsize= 11, maxiter= 11, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for MLPClassifier(hidden_layer_sizes=39, max_iter=300, random_state=42) using train dataset = 0.7267604303787252\n",
      "f1-Score for MLPClassifier(hidden_layer_sizes=39, max_iter=300, random_state=42) using test dataset = 0.7049761104908163\n"
     ]
    }
   ],
   "source": [
    "model_test, test_score = m_pso.model_predict(X_test_vec, y_test, best_pso[0])\n",
    "print(f\"f1-Score for {model_test} using train dataset = {evaluate(model_test, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {model_test} using test dataset = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for GradientBoostingClassifier(random_state=42) using train dataset = 0.6007712358693563\n",
      "f1-Score for GradientBoostingClassifier(random_state=42) using test dataset = 0.6561135045510046\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(gb_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "gb_model.fit(X_train_vec, y_train)\n",
    "pred = gb_model.predict(X_test_vec)\n",
    "f1_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f\"f1-Score for {gb_model} using train dataset = {evaluate(gb_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {gb_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "New best for swarm at iteration 1: [95.98239272  0.26111844] 0.36838689960896853\n",
      "New best for swarm at iteration 1: [100.    0.3] 0.3612329427108839\n",
      "Best after iteration 1: [100.    0.3] 0.3612329427108839\n",
      "New best for swarm at iteration 2: [88.72164508  0.3       ] 0.35677324205087024\n",
      "Best after iteration 2: [88.72164508  0.3       ] 0.35677324205087024\n",
      "Best after iteration 3: [88.72164508  0.3       ] 0.35677324205087024\n",
      "New best for swarm at iteration 4: [99.09639013  0.26040618] 0.35477606571704867\n",
      "Best after iteration 4: [99.09639013  0.26040618] 0.35477606571704867\n",
      "New best for swarm at iteration 5: [99.41481293  0.29981526] 0.3448274189335738\n",
      "Best after iteration 5: [99.41481293  0.29981526] 0.3448274189335738\n",
      "New best for swarm at iteration 6: [99.19509287  0.2997229 ] 0.3423776351796526\n",
      "Best after iteration 6: [99.19509287  0.2997229 ] 0.3423776351796526\n",
      "Best after iteration 7: [99.19509287  0.2997229 ] 0.3423776351796526\n",
      "Best after iteration 8: [99.19509287  0.2997229 ] 0.3423776351796526\n",
      "Best after iteration 9: [99.19509287  0.2997229 ] 0.3423776351796526\n",
      "Best after iteration 10: [99.19509287  0.2997229 ] 0.3423776351796526\n",
      "Best after iteration 11: [99.19509287  0.2997229 ] 0.3423776351796526\n",
      "Stopping search: maximum iterations reached --> 11\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "gb_model = GradientBoostingClassifier\n",
    "\n",
    "# Set hyperparameters to optimize and variables's type\n",
    "param_to_opt = {'n_estimators' : int, 'learning_rate': float}\n",
    "\n",
    "# Set lower and upper boundarys\n",
    "lb = [5, 0.01]\n",
    "ub = [100, 0.3]\n",
    "\n",
    "# Set model in class\n",
    "m_pso.model_set(gb_model, param_to_opt, extra_params= {'random_state':42, 'max_depth' : 3})\n",
    "\n",
    "# Seek best hyperparameters\n",
    "best_pso = pso(m_pso.model_optimize, lb, ub, swarmsize= 11, maxiter= 11, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for GradientBoostingClassifier(learning_rate=0.2997228955422446, n_estimators=99,\n",
      "                           random_state=42) using train dataset = 0.6576223648203474\n",
      "f1-Score for GradientBoostingClassifier(learning_rate=0.2997228955422446, n_estimators=99,\n",
      "                           random_state=42) using test dataset = 0.6601924117549118\n"
     ]
    }
   ],
   "source": [
    "model_test, test_score = m_pso.model_predict(X_test_vec, y_test, best_pso[0])\n",
    "print(f\"f1-Score for {model_test} using train dataset = {evaluate(model_test, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {model_test} using test dataset = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for LogisticRegression(random_state=42) using train dataset = 0.6473471869977288\n",
      "f1-Score for LogisticRegression(random_state=42) using test dataset = 0.6513659951159951\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(lr_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "lr_model.fit(X_train_vec, y_train)\n",
    "pred = lr_model.predict(X_test_vec)\n",
    "f1_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f\"f1-Score for {lr_model} using train dataset = {evaluate(lr_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {lr_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hip = {\n",
    "    \"RandomForestClassifier\" :{\n",
    "        \"best_hip\" : {\"n_estimators\" : 277, \"cpp_alpha\" : 0.0, \"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.7805201890650219,\n",
    "        \"f1_score_test\" : 0.8718649406149406      \n",
    "    },\n",
    "    \"RandomForestClassifier_Default\" :{\n",
    "        \"best_hip\" : {\"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.7487754934936588,\n",
    "        \"f1_score_test\" : 0.8530094905094905      \n",
    "    },\n",
    "    \"MLPClassifier\" :{\n",
    "        \"best_hip\" : {\"max_iter\" : 200, \"random_state\" : 42, \"hidden_layer_sizes\" : 39},\n",
    "        \"f1_score_train\" : 0.7267604303787252,\n",
    "        \"f1_score_test\" : 0.7049761104908163      \n",
    "    },\n",
    "    \"MLPClassifier_Default\" :{\n",
    "        \"best_hip\" : {\"max_iter\" : 300, \"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.7534351410888883,\n",
    "        \"f1_score_test\" : 0.7338108072483072      \n",
    "    },\n",
    "    \"GradientBoostingClassifier\" :{\n",
    "        \"best_hip\" : {\"learning_rate\" : 0.2997228955422446, \"n_estimators\" : 99, \"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.6576223648203474,\n",
    "        \"f1_score_test\" : 0.6601924117549118      \n",
    "    },\n",
    "    \"GradientBoostingClassifier_Default\" :{\n",
    "        \"best_hip\" : {\"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.6007712358693563,\n",
    "        \"f1_score_test\" : 0.6561135045510046      \n",
    "    },\n",
    "    \"LogisticRegression_Default\" :{\n",
    "        \"best_hip\" : {\"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.6473471869977288,\n",
    "        \"f1_score_test\" : 0.6513659951159951      \n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "save(\"best_models_subject\", best_hip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "\n",
    "start = (subject-1)*50\n",
    "end = start + 50\n",
    "\n",
    "X_que_filt = np.array(X_que)[start:end]\n",
    "y_que_filt = np.array(y_que)[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(X_que_filt, y_que_filt)\n",
    "\n",
    "# Make X vector\n",
    "X_train_vec = make_it_vector(X_train)\n",
    "X_test_vec = make_it_vector(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pso = model_pso(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for RandomForestClassifier(random_state=42) using train dataset = 0.9703703703703704\n",
      "f1-Score for RandomForestClassifier(random_state=42) using test dataset = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(rf_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "pred = rf_model.predict(X_test_vec)\n",
    "\n",
    "print(f\"f1-Score for {rf_model} using train dataset = {evaluate(rf_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {rf_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "New best for swarm at iteration 1: [  0.         115.87394552] 0.02962962962962956\n",
      "Stopping search: Swarm best objective change less than 1e-08\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "rf_model = RandomForestClassifier\n",
    "\n",
    "# Set hyperparameters to optimize and variables's type\n",
    "param_to_opt = {'ccp_alpha' : float, 'n_estimators' : int}\n",
    "\n",
    "# Set lower and upper boundarys\n",
    "lb = [0.0, 1]\n",
    "ub = [0.04, 300]\n",
    "\n",
    "# Set model in class\n",
    "m_pso.model_set(rf_model, param_to_opt, extra_params= {'random_state' : 42})\n",
    "\n",
    "# Seek best hyperparameters\n",
    "best_pso = pso(m_pso.model_optimize, lb, ub, swarmsize= 11, maxiter= 11, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for RandomForestClassifier(n_estimators=115, random_state=42) using train dataset = 0.9703703703703704\n",
      "f1-Score for RandomForestClassifier(n_estimators=115, random_state=42) using test dataset = 1.0\n"
     ]
    }
   ],
   "source": [
    "model_test, test_score = m_pso.model_predict(X_test_vec, y_test, best_pso[0])\n",
    "print(f\"f1-Score for {model_test} using train dataset = {evaluate(model_test, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {model_test} using test dataset = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for MLPClassifier(max_iter=300, random_state=42) using train dataset = 1.0\n",
      "f1-Score for MLPClassifier(max_iter=300, random_state=42) using test dataset = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "mlp_model = MLPClassifier(max_iter=300, random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(mlp_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "mlp_model.fit(X_train_vec, y_train)\n",
    "pred = mlp_model.predict(X_test_vec)\n",
    "f1_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f\"f1-Score for {mlp_model} using train dataset = {evaluate(mlp_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {mlp_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "Best after iteration 1: [62.45819404] 0.0\n",
      "Best after iteration 2: [62.45819404] 0.0\n",
      "Best after iteration 3: [62.45819404] 0.0\n",
      "Best after iteration 4: [62.45819404] 0.0\n",
      "Best after iteration 5: [62.45819404] 0.0\n",
      "Best after iteration 6: [62.45819404] 0.0\n",
      "Best after iteration 7: [62.45819404] 0.0\n",
      "Best after iteration 8: [62.45819404] 0.0\n",
      "Best after iteration 9: [62.45819404] 0.0\n",
      "Best after iteration 10: [62.45819404] 0.0\n",
      "Best after iteration 11: [62.45819404] 0.0\n",
      "Stopping search: maximum iterations reached --> 11\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "mlp_model = MLPClassifier\n",
    "\n",
    "# Set hyperparameters to optimize and variables's type\n",
    "param_to_opt = {'hidden_layer_sizes' : int}\n",
    "\n",
    "# Set lower and upper boundarys\n",
    "lb = [3]\n",
    "ub = [100]\n",
    "\n",
    "# Set model in class\n",
    "m_pso.model_set(mlp_model, param_to_opt, extra_params= {'max_iter': 200, 'random_state':42})\n",
    "\n",
    "# Seek best hyperparameters\n",
    "best_pso = pso(m_pso.model_optimize, lb, ub, swarmsize= 11, maxiter= 11, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for MLPClassifier(hidden_layer_sizes=62, random_state=42) using train dataset = 1.0\n",
      "f1-Score for MLPClassifier(hidden_layer_sizes=62, random_state=42) using test dataset = 1.0\n"
     ]
    }
   ],
   "source": [
    "model_test, test_score = m_pso.model_predict(X_test_vec, y_test, best_pso[0])\n",
    "print(f\"f1-Score for {model_test} using train dataset = {evaluate(model_test, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {model_test} using test dataset = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for GradientBoostingClassifier(random_state=42) using train dataset = 0.7222222222222221\n",
      "f1-Score for GradientBoostingClassifier(random_state=42) using test dataset = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(gb_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "gb_model.fit(X_train_vec, y_train)\n",
    "pred = gb_model.predict(X_test_vec)\n",
    "f1_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f\"f1-Score for {gb_model} using train dataset = {evaluate(gb_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {gb_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No constraints given.\n",
      "Best after iteration 1: [17.17444637  0.19116703] 0.24814814814814823\n",
      "New best for swarm at iteration 2: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 2: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 3: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 4: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 5: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 6: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 7: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 8: [5.         0.12771015] 0.21851851851851856\n",
      "Best after iteration 9: [5.         0.12771015] 0.21851851851851856\n",
      "New best for swarm at iteration 10: [5.        0.1322785] 0.1955555555555556\n",
      "Best after iteration 10: [5.        0.1322785] 0.1955555555555556\n",
      "Best after iteration 11: [5.        0.1322785] 0.1955555555555556\n",
      "Stopping search: maximum iterations reached --> 11\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "gb_model = GradientBoostingClassifier\n",
    "\n",
    "# Set hyperparameters to optimize and variables's type\n",
    "param_to_opt = {'n_estimators' : int, 'learning_rate': float}\n",
    "\n",
    "# Set lower and upper boundarys\n",
    "lb = [5, 0.01]\n",
    "ub = [100, 0.3]\n",
    "\n",
    "# Set model in class\n",
    "m_pso.model_set(gb_model, param_to_opt, extra_params= {'random_state':42, 'max_depth' : 3})\n",
    "\n",
    "# Seek best hyperparameters\n",
    "best_pso = pso(m_pso.model_optimize, lb, ub, swarmsize= 11, maxiter= 11, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for GradientBoostingClassifier(learning_rate=0.13227850217356052, n_estimators=5,\n",
      "                           random_state=42) using train dataset = 0.8044444444444444\n",
      "f1-Score for GradientBoostingClassifier(learning_rate=0.13227850217356052, n_estimators=5,\n",
      "                           random_state=42) using test dataset = 1.0\n"
     ]
    }
   ],
   "source": [
    "model_test, test_score = m_pso.model_predict(X_test_vec, y_test, best_pso[0])\n",
    "print(f\"f1-Score for {model_test} using train dataset = {evaluate(model_test, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {model_test} using test dataset = {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-Score for LogisticRegression(random_state=42) using train dataset = 1.0\n",
      "f1-Score for LogisticRegression(random_state=42) using test dataset = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "evaluate(lr_model, X_train_vec, y_train)\n",
    "\n",
    "# Fit and test\n",
    "lr_model.fit(X_train_vec, y_train)\n",
    "pred = lr_model.predict(X_test_vec)\n",
    "f1_score(y_test, pred, average='macro')\n",
    "\n",
    "print(f\"f1-Score for {lr_model} using train dataset = {evaluate(lr_model, X_train_vec, y_train).mean()}\")\n",
    "print(f\"f1-Score for {lr_model} using test dataset = {f1_score(y_test, pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hip = {\n",
    "    \"RandomForestClassifier\" :{\n",
    "        \"best_hip\" : {\"n_estimators\" : 115, \"cpp_alpha\" : 0.0, \"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.9703703703703704,\n",
    "        \"f1_score_test\" : 1.0      \n",
    "    },\n",
    "    \"RandomForestClassifier_Default\" :{\n",
    "        \"best_hip\" : {\"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.9703703703703704,\n",
    "        \"f1_score_test\" : 1.0     \n",
    "    },\n",
    "    \"MLPClassifier\" :{\n",
    "        \"best_hip\" : {\"max_iter\" : 200, \"random_state\" : 42, \"hidden_layer_sizes\" : 62},\n",
    "        \"f1_score_train\" : 1.0,\n",
    "        \"f1_score_test\" : 1.0\n",
    "    },\n",
    "    \"MLPClassifier_Default\" :{\n",
    "        \"best_hip\" : {\"max_iter\" : 300, \"random_state\" : 42},\n",
    "        \"f1_score_train\" : 1.0,\n",
    "        \"f1_score_test\" : 1.0\n",
    "    },\n",
    "    \"GradientBoostingClassifier\" :{\n",
    "        \"best_hip\" : {\"learning_rate\" : 0.13227850217356052, \"n_estimators\" : 5, \"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.8044444444444444,\n",
    "        \"f1_score_test\" : 1.0      \n",
    "    },\n",
    "    \"GradientBoostingClassifier_Default\" :{\n",
    "        \"best_hip\" : {\"random_state\" : 42},\n",
    "        \"f1_score_train\" : 0.7222222222222221,\n",
    "        \"f1_score_test\" : 1.0      \n",
    "    },\n",
    "    \"LogisticRegression_Default\" :{\n",
    "        \"best_hip\" : {\"random_state\" : 42},\n",
    "        \"f1_score_train\" : 1.0,\n",
    "        \"f1_score_test\" : 1.0\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "save(\"best_models_question\", best_hip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_hip</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>{'n_estimators': 277, 'cpp_alpha': 0.0, 'rando...</td>\n",
       "      <td>0.780520</td>\n",
       "      <td>0.871865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_Default</th>\n",
       "      <td>{'random_state': 42}</td>\n",
       "      <td>0.748775</td>\n",
       "      <td>0.853009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>{'max_iter': 200, 'random_state': 42, 'hidden_...</td>\n",
       "      <td>0.726760</td>\n",
       "      <td>0.704976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_Default</th>\n",
       "      <td>{'max_iter': 300, 'random_state': 42}</td>\n",
       "      <td>0.753435</td>\n",
       "      <td>0.733811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>{'learning_rate': 0.2997228955422446, 'n_estim...</td>\n",
       "      <td>0.657622</td>\n",
       "      <td>0.660192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_Default</th>\n",
       "      <td>{'random_state': 42}</td>\n",
       "      <td>0.600771</td>\n",
       "      <td>0.656114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_Default</th>\n",
       "      <td>{'random_state': 42}</td>\n",
       "      <td>0.647347</td>\n",
       "      <td>0.651366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             best_hip  \\\n",
       "RandomForestClassifier              {'n_estimators': 277, 'cpp_alpha': 0.0, 'rando...   \n",
       "RandomForestClassifier_Default                                   {'random_state': 42}   \n",
       "MLPClassifier                       {'max_iter': 200, 'random_state': 42, 'hidden_...   \n",
       "MLPClassifier_Default                           {'max_iter': 300, 'random_state': 42}   \n",
       "GradientBoostingClassifier          {'learning_rate': 0.2997228955422446, 'n_estim...   \n",
       "GradientBoostingClassifier_Default                               {'random_state': 42}   \n",
       "LogisticRegression_Default                                       {'random_state': 42}   \n",
       "\n",
       "                                    f1_score_train  f1_score_test  \n",
       "RandomForestClassifier                    0.780520       0.871865  \n",
       "RandomForestClassifier_Default            0.748775       0.853009  \n",
       "MLPClassifier                             0.726760       0.704976  \n",
       "MLPClassifier_Default                     0.753435       0.733811  \n",
       "GradientBoostingClassifier                0.657622       0.660192  \n",
       "GradientBoostingClassifier_Default        0.600771       0.656114  \n",
       "LogisticRegression_Default                0.647347       0.651366  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(load(\"best_models_subject\"), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
