{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/unicamp.png\" width=\"150\" height=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MO444/MC886 - Aprendizado de Máquina e Reconhecimento de Padrões\n",
    "\n",
    "Esse trabalho foi feito pelos seguintes membros:\n",
    "\n",
    "- Germán Darío Buitrago Salazar - 164321\n",
    "- Giovanna Relvas Bartilotti - 023907\n",
    "- Lucas Zanco Ladeira - 188951\n",
    "- Rafael Scherer - 204990 \n",
    "\n",
    "O código original deste projeto está disponível no [repositório do Github](https://github.com/lucaslzl/mo444_p4_qea).\n",
    "\n",
    "Vídeo de apresentação [link](https://youtube.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalho Final - Serviço de FAQ para os Objetivos de Desenvolvimento Sustentável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Declaração do Problema</b>\n",
    "\n",
    "\"Este trabalho tem como objetivo construir um sistema de Aprendizado de Máquina para solucionar um problema escolhido pelo grupo inserido em um dos Objetivos de Desenvolvimento Sustentável (ODS) da ONU. O trabalho do seu grupo é encontrar uma solução adequada para o problema escolhido.\"\n",
    "\n",
    "Neste trabalho foi construído um serviço de FAQ para tirar dúvidas das pessoas sobre os Objetivos de Desenvolvimento Sustentável. Para tal, foram utilizadas algumas estratégias de processamento de linguagem natural, modelos supervisionados, e bibliotecas para auxiliar na construção da base de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cenário\n",
    "\n",
    "De acordo com [1], desenvolvimento sustentável se refere a um modelo de desenvolvimento econômico, social e político que esteja em harmonia com o meio ambiente. Isso significa utilizar conscientemente os recursos disponíveis para que não acabe com o meio ambiente. Ele é imprescindível para o futuro da população humana e dos outros animais que habitam o planeta terra. As Nações Unidas fizeram um acordo em 2015 com 195 países para trabalhar em 17 objetivos de forma a mudar o mundo para melhor. Esses objetivos estão distribuídos em ações para acabar com a pobreza, proteger o meio ambiente e o clima e garantir que as pessoas em todos os lugares possam desfrutar de paz e prosperidade. É possível observar na figura a seguir esses objetivos.\n",
    "\n",
    "<img src=\"imgs/ods_pt.png\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base de Dados\n",
    "\n",
    "A base de dados utilizada neste trabalho compreende 10 perguntas e respostas para cada um dos 16 primeiros objetivos. Ela foi construída manualmente pelos 4 integrantes do grupo, sendo que, cada integrante focou em 4 objetivos. As perguntas e respostas foram retiradas do relatório das Nações Unidas de 2020 [2]. Portanto, a base de dados tem 160 pares de perguntas e respostas. Para desenvolver um modelo supervisionado vimos que não seria o suficiente, pois cada resposta compreende uma classe distinta. Para resolver esse problema, uma biblioteca chamada NLPAug [3] foi utilizada, a qual tem como objetivo criar mais dados textuais a partir de uma base existente. Com ela foram criados mais 4 registros para cada par fazendo pequenas substituições nas frases, crescendo a base de dados para 800 registros. Essas substituições se referem a utilizar o modelo <i>distilbert</i> para buscar palavras próximas no embedding, e o modelo <i>wordnet</i> para buscar sinônimos de palavras das perguntas.\n",
    "\n",
    "Para observar quais foram as perguntas criadas execute o código a seguir modificando o nome do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fname = '1_poverty_eradication'\n",
    "df = pd.read_excel(f'data/{fname}.xlsx')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the objective of Sustainable Developme...</td>\n",
       "      <td>Eradicate poverty in all forms and everywhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many dollars does a person of extreme pove...</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What proportion of men, women and children of ...</td>\n",
       "      <td>half</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHow to ensure a significant mobilization of ...</td>\n",
       "      <td>From a variety of sources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why create solid policy frameworks?</td>\n",
       "      <td>to support investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By 2030, how many men will have equal rights t...</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is expected about the exposure and vulner...</td>\n",
       "      <td>reduce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cite an objective on implementing programs and...</td>\n",
       "      <td>End poverty in all its dimensions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nWhat is the level of implementation of socia...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For how many men and women, by 2030 will have ...</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  What is the objective of Sustainable Developme...   \n",
       "1  How many dollars does a person of extreme pove...   \n",
       "2  What proportion of men, women and children of ...   \n",
       "3  \\nHow to ensure a significant mobilization of ...   \n",
       "4               Why create solid policy frameworks?    \n",
       "5  By 2030, how many men will have equal rights t...   \n",
       "6  What is expected about the exposure and vulner...   \n",
       "7  cite an objective on implementing programs and...   \n",
       "8  \\nWhat is the level of implementation of socia...   \n",
       "9  For how many men and women, by 2030 will have ...   \n",
       "\n",
       "                                          Answer  \n",
       "0  Eradicate poverty in all forms and everywhere  \n",
       "1                                            1.9  \n",
       "2                                           half  \n",
       "3                      From a variety of sources  \n",
       "4                         to support investments  \n",
       "5                                            all  \n",
       "6                                         reduce  \n",
       "7              End poverty in all its dimensions  \n",
       "8                                       national  \n",
       "9                                            all  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solução\n",
    "\n",
    "Todos os anos as Nações Unidas publicam um relatório [2] com o avanço dessas ações do ODS. No entanto, esta forma de publicação não é acessível e nem chamativo para a maior parte das pessoas. Sendo assim, é necessário criar uma maneira interativa de levar essas informações para a população. Um serviço de FAQ pode ajudar nesse sentido, com a característica de fazer perguntas abertamente e receber alguma resposta. Para tal, desenvolvemos esse serviço o qual utiliza processamento de linguagem natural (PLN) para identificar sobre qual objetivo o usuário deseja conhecer e qual é a resposta mais provável. \n",
    "\n",
    "O serviço utiliza 2 níveis modelos, o primeiro para predizer qual é o objetivo que a pergunta se refere, e o segundo qual é a provável resposta sobre o objetivo predito. Neste trabalho consideramos 16 objetivos, sendo assim, são necessários 17 modelos. A vantagem de utilizar uma estrutura de classificação hierárquica para classificar uma subclasse é que esses classificadores de subclasses são treinados especificamente para cada classe, fazendo com que ao invés de ter que classificar uma subclasse tendo 800 outras opções, cada classificador possui apenas as subclasses referentes a sua classe principal.\n",
    "\n",
    "Antes de treinar os modelos os dados passaram por um pre-processamento para melhorar a qualidade dos dados e transformá-los em uma representação que modelos consigam entender. Primeiramente os dados foram limpos removendo caracteres especiais, como por exemplo \"<i>\\n</i>\". Considerando que os dados são textuais, utilizamos a classe Doc2Vec da biblioteca gensim para treinar um modelo de sentence embedding e transformar os textos em vetores de 50 dimensões. A quantidade de dimensões foi escolhida com testes empíricos. \n",
    "\n",
    "Os dados foram duplicados e formatados de acordo com o modelo destino. Nos dados destinados a predição de qual objetivo a pergunta se refere, foi criada uma <i>feature</i> da classe que varia de 1-16 de acordo com os objetivos. No outro conjunto de dados foi criada uma <i>feature</i> da classe com cada pergunta possível, variando de 1-160. Mesmo que para cada modelo deste nível apenas sejam utilizadas 10 variações de perguntas, essa organização facilita identificar qual pergunta é em uma lista. Após, foram aplicados experimentos com diferentes modelos, comparando a configuração de hiperparâmetros padrão da biblioteca scikit-learn, e também, o tuning deles como será apresentado na seção de desenvolvimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Desenvolvimento\n",
    "\n",
    "Apresentaremos aqui alguns dos algoritmos utilizados no desenvolvimento da solução, como a estratégia de tuning dos modelos. Por fim, o modelo que obteve melhor resultado nos testes. O código fonte está distribuído em diferentes notebooks sendo:\n",
    "- augment: Estratégia de data augmentation\n",
    "- modelling: Processamento dos dados, treinamento de modelos e criação dos gráficos com resultados\n",
    "- tunning: Estratégia de tuning dos hiperparâmetros\n",
    "- talk_to_me: Notebook para testar a solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(text, times=2):\n",
    "\n",
    "    augmented = []\n",
    "        \n",
    "    # Iterate x times\n",
    "    for i in range(times):\n",
    "        \n",
    "        # Substitute with distilbert\n",
    "        aug = naw.ContextualWordEmbsAug(\n",
    "            model_path='distilbert-base-uncased', action=\"substitute\")\n",
    "        augmented.append(aug.augment(text))\n",
    "\n",
    "        # Substitute with wordnet\n",
    "        aug = naw.SynonymAug(aug_src='wordnet')\n",
    "        augmented.append(aug.augment(text))\n",
    "    \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokenized = [word_tokenize(c.lower()) for c in corpus]\n",
    "\n",
    "# Tag\n",
    "tagged = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized)]\n",
    "\n",
    "# Train model\n",
    "model = Doc2Vec(tagged, vector_size=50, window=2, min_count=1, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which subject?\n",
    "class_sub = {}\n",
    "X_sub, y_sub = [], []\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "\n",
    "    class_sub[str(i+1)] = f\n",
    "    X_sub.extend(files[f]['question'].values)\n",
    "    y_sub.extend([str(i+1)]*len(files[f]['question'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which question?\n",
    "class_que = {}\n",
    "X_que, y_que = [], []\n",
    "count = 0\n",
    "last = ''\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    \n",
    "    for j, row in files[f].iterrows():\n",
    "        \n",
    "        que = row['question']\n",
    "        ans = row['answer']\n",
    "        \n",
    "        if last != ans:\n",
    "            last = ans\n",
    "            count += 1\n",
    "        \n",
    "        class_que[str(count)] = ans\n",
    "        X_que.append(que)\n",
    "        y_que.append(str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Tuning\n",
    "\n",
    "A busca de hiperparâmetros foi realizada aplicando o algoritmo de PSO, que otimiza iterativamente uma solução candidata aplicando uma medida de qualidade G(x). Devido a que a avaliação dos modelos classificatórios usa o f1-score como métrica de acurácia do sistema escolhida, decidiu-se otimizar dita medida minimizando seu valor. Assim, para sua aplicação, a medida foi ajeitada para achar o menor valor possível, como visto na equacionamento abaixo.\n",
    "\n",
    "$$ G(x) = 1 - {f_1Score}$$\n",
    "\n",
    "O resultado da busca está na tabela seguinte. Para o modelo de Random Forest, a busca foi feita para encontrar o melhor número de estimadores `n_estimators` e o melhor fator pra fazer prunning nas árvores `ccp_alpha`; no MLP foi realizada para encontrar o melhor número de neurônios `hidden_layer_sizes`; no Gradient Boosting foi usada no `learning_rate` e no número de estimadores `n_estimators`. De todos os modelos treinados, o melhor resultado foi o Random Forest ao usar 227 estimadores e `ccp_alpha` zerado. Comparado com o métrica do cross validation, o modelo melhorou em 3.2%.\n",
    "\n",
    "| Modelo                             | Melhores Hiperparâmetros                                                         | F1-Score Cross-Validation | F1-Score Test |\n",
    "|------------------------------------|----------------------------------------------------------------------------------|---------------------------|---------------|\n",
    "| RandomForestClassifier_Default     | {\"random_state\" : 42},                                                           | 0.748775                  | 0.853009      |\n",
    "| RandomForestClassifier             | {\"n_estimators\" : 277, \"ccp_alpha\" : 0.0, \"random_state\" : 42}                   | 0.780520                  | 0.871865      |\n",
    "| MLPClassifier_Default              | {\"max_iter\" : 300, \"random_state\" : 42}                                          | 0.753435                  | 0.733811      |\n",
    "| MLPClassifier                      | {\"max_iter\" : 200, \"random_state\" : 42, \"hidden_layer_sizes\" : 39}               | 0.726760                  | 0.704976      |\n",
    "| GradientBoostingClassifier_Default | {\"random_state\" : 42}                                                            | 0.600771                  | 0.656114      |\n",
    "| GradientBoostingClassifier         | {\"learning_rate\" : 0.2997228955422446, \"n_estimators\" : 99, \"random_state\" : 42} | 0.657622                  | 0.660192      |\n",
    "| LogisticRegression_Default         | {\"random_state\" : 42}                                                            | 0.647347                  | 0.651366      |\n",
    "\n",
    "Os resultados do tuning para as question estão na tabela a seguir. Observe que os melhores são os obtidos com o MLP, RandomForest e Logistic Regression.\n",
    "\n",
    "\n",
    "| Modelo                             | Melhores Hiperparâmetros                                                         | F1-Score Cross-Validation | F1-Score Test |\n",
    "|------------------------------------|----------------------------------------------------------------------------------|---------------------------|---------------|\n",
    "| RandomForestClassifier_Default     | {\"random_state\" : 42},                                                           | 0.970370                  | 1.0           |\n",
    "| RandomForestClassifier             | {\"n_estimators\" : 115, \"ccp_alpha\" : 0.0, \"random_state\" : 42}                   | 0.970370                  | 1.0           |\n",
    "| MLPClassifier_Default              | {\"max_iter\" : 300, \"random_state\" : 42}                                          | 1.0                       | 1.0           |\n",
    "| MLPClassifier                      | {\"max_iter\" : 200, \"random_state\" : 42, \"hidden_layer_sizes\" : 62}               | 1.0                       | 1.0           |\n",
    "| GradientBoostingClassifier_Default | {\"random_state\" : 42}                                                            | 0.804444                  | 1.0           |\n",
    "| GradientBoostingClassifier         | {\"learning_rate\" : 0.13227850217356052, \"n_estimators\" : 5, \"random_state\" : 42} | 0.722222                  | 1.0           |\n",
    "| LogisticRegression_Default         | {\"random_state\" : 42}                                                            | 1.0                       | 1.0           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metodologia e Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modelo de classificação tem como objetivo decidir em qual classe uma nova observação pertence dentre das classes possíveis.  A avaliação de um modelo de classificação é feita a partir da comparação entre as classes preditas pelo modelo e as classes verdadeiras de cada exemplo. Todas as métricas de classificação têm como objetivo comum medir quão distante o modelo está da classificação perfeita, porém fazem isto de formas diferentes. Cada algoritmo foi avaliado com base na F1-Score: É uma medida que considera tanto a precision quanto o recall para gerar uma pontuação, sendo a melhor medida para se avaliar um classificador.\n",
    "\n",
    "Para selecionar o melhor modelo consideramos as seguintes opções:\n",
    "- RandomForest\n",
    "- Multilayer Perceptron\n",
    "- Gradient Boosting\n",
    "- Logistic Regression\n",
    "\n",
    "Esses foram testados com e sem tuning dos hiperparâmetros como apresentados anteriormente, como também comparados de acordo com cada objetivo. Os resultados serão apresentados a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='imgs/res_sub_1.png'></td><td><img src='imgs/res_sub_2.png'></td><td><img src='imgs/res_sub_3.png'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='imgs/res_sub_4.png'></td><td><img src='imgs/res_sub_5.png'></td><td><img src='imgs/res_sub_6.png'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='imgs/res_sub_7.png'></td><td><img src='imgs/res_sub_8.png'></td><td><img src='imgs/res_sub_9.png'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='imgs/res_sub_10.png'></td><td><img src='imgs/res_sub_11.png'></td><td><img src='imgs/res_sub_12.png'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='imgs/res_sub_13.png'></td><td><img src='imgs/res_sub_14.png'></td><td><img src='imgs/res_sub_15.png'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/res_sub_16.png\" width=\"320\" height=\"320\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que para a maior parte dos objetivos o modelo Random Forest se saiu igual ou melhor que os outros. Com essa comparação ele foi escolhido para ser utilizado no serviço."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "O presente trabalho estudou a eficiência de um classificador de questões na\n",
    "língua inglesa, montado com aprendizado de máquina supervisionado. O principal objetivo deste trabalho foi concluído, uma vez que os resultados obtidos pelo classificador são extremamente satisfatorios para construção de uma FAQ considerando os Objetivos de Desenvolvimento Sustentável (ODS) da ONU.\n",
    "\n",
    "Podemos considerar os resultados obtidos pelo classificador como extremamente satisfatórios, tendo uma pontuação de 80% durante a classificação da classe bruta e uma média próxima de 95% entre os classificadores secundários, considerando o algoritmo *Random Forest*.\n",
    "\n",
    "Ao final deste trabalho, diversos caminhos diferentes surgiram para trabalhos futuros, entre as quais se destacam a criação de um agente virtual para apoio ao trabalho dos estudantes, baseado em classificadores hierárquicos para identificar o módulo e submódulo que possui a resposta para a pergunta de um usuário. Além disso também poderia ser explorada a SimpleTransformers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "[1] P. Guitarrara, \"Desenvolvimento sustentável\", acessado em: 17/07/2021. Disponível em: https://brasilescola.uol.com.br/geografia/desenvolvimento-sustentavel.htm.\n",
    "\n",
    "[2] UN, \"The Sustainable Development Goals Report 2020\", acessado em: 17/07/2021. Disponível em: https://unstats.un.org/sdgs/report/2020/The-Sustainable-Development-Goals-Report-2020.pdf.\n",
    "\n",
    "[3] \"NLP Augmentation\", acessado em: 17/07/2021. Disponível em: https://github.com/makcedward/nlpaug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Contribuições\n",
    "<br>\n",
    "O membro do grupo <b>Germán Darío Buitrago Salazar</b> contribuiu com a criação da base de dados, estratégia de tuning de modelos, escrita do relatório, e geração do resultados.\n",
    "\n",
    "O membro do grupo <b>Giovanna Relvas Bartilotti</b> contribuiu com a criação da base de dados, escrita do relatório, vídeo.\n",
    "\n",
    "O membro do grupo <b>Lucas Zanco Ladeira</b> contribuiu com o desenvolvimento da solução na parte de augmentação, treinamento e uso do embedding (Doc2Vec), preparação dos dados, modelagem inicial, criação do notebook talk_to_me, e escrita deste relatório.\n",
    "\n",
    "O membro do grupo <b>Rafael Scherer</b> contribuiu com a criação da base de dados, desenvolvimento e geração dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observações</b>\n",
    "\n",
    "A ideia inicial do trabalho era de usar um modelo de transformer (BERT, Roberta, etc), mas tivemos alguns problemas com a implementação de bibliotecas. Pensamos em utilizar SimpleTransformers, Pytorch ou Tensorflow, mas pelo tempo disponível achamos melhor utilizar uma arquitetura mais simples da solução."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e36b5bde22ecaf5d959c03a949a4cedc58ded8233ad7058ca039ed514de4674f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
